{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchmetrics in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.4.0.post0)\n",
      "Requirement already satisfied: numpy>1.20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torchmetrics) (1.26.4)\n",
      "Requirement already satisfied: packaging>17.1 in /Users/lennartzahn/Library/Python/3.12/lib/python/site-packages (from torchmetrics) (23.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torchmetrics) (2.4.0.dev20240409)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torchmetrics) (0.11.2)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (69.2.0)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.11.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.10.0->torchmetrics) (3.13.3)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.10.0->torchmetrics) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.10.0->torchmetrics) (2024.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch_lightning in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.4.9)\n",
      "Collecting pytorch_lightning\n",
      "  Using cached pytorch_lightning-2.2.5-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pytorch_lightning) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.13.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pytorch_lightning) (2.4.0.dev20240409)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pytorch_lightning) (4.66.2)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pytorch_lightning) (6.0.1)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2024.3.1)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pytorch_lightning) (1.4.0.post0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/lennartzahn/Library/Python/3.12/lib/python/site-packages (from pytorch_lightning) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pytorch_lightning) (4.11.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pytorch_lightning) (0.11.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.9.5)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from lightning-utilities>=0.8.0->pytorch_lightning) (69.2.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.13.0->pytorch_lightning) (3.13.3)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.13.0->pytorch_lightning) (1.12)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.13.0->pytorch_lightning) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.13.0->pytorch_lightning) (3.1.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.9.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->torch>=1.13.0->pytorch_lightning) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sympy->torch>=1.13.0->pytorch_lightning) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.6)\n",
      "Downloading pytorch_lightning-2.2.5-py3-none-any.whl (802 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.3/802.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytorch_lightning\n",
      "  Attempting uninstall: pytorch_lightning\n",
      "    Found existing installation: pytorch-lightning 1.4.9\n",
      "    Uninstalling pytorch-lightning-1.4.9:\n",
      "      Successfully uninstalled pytorch-lightning-1.4.9\n",
      "Successfully installed pytorch_lightning-2.2.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type                   | Params\n",
      "---------------------------------------------------------\n",
      "0 | enc_embedding | DataEmbedding_inverted | 1.1 K \n",
      "1 | encoder       | ModuleList             | 66.9 K\n",
      "2 | projector     | Linear                 | 520   \n",
      "---------------------------------------------------------\n",
      "68.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "68.6 K    Total params\n",
      "0.274     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0007e391050845e68dfe4af35848fd5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (16) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f31585ae2b041b886e2ba3ce4951a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f9cf1a4bcad4862bf5dc4438199a6cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6f347626864eba90bf4fae883aa3e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fffdf83fa70d455491d18fad82e1f582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c82a08f65e864e00bea2f47b481f3de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d0b4c10b64142fd9aebb9e6c14e2bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e42516bbc14648599b384be3f2c63e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e28cf2e080604b39be2dbe43f857590d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc2b8d9f755b411e99f1dd8e2c8c43a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec1c3e20b954399ae100b9b3a677b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b212682b3692423c86d94c73a94a30af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7509a23baa442428054ffb8ecf672a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bfc2a113b524ca1bc1e28248f250ff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9dfff7934484ecfbb715ba467db6182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a413462ecf4db19c826cd2f554816b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68aa6dfcc9de4e97956820a28d66ba4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b867f32134d84a9d945c2943c17ca808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a30c363908142d3bbdd2e89d33fdc95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329e4c14771b4c30a9bb77958f6a8d16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6273bdf0648f45cfab71c2b2dc65d90a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30cc6c492fbb44fda443375f672d11fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Define TriangularCausalMask\n",
    "class TriangularCausalMask():\n",
    "    def __init__(self, B, L, device=\"cpu\"):\n",
    "        mask_shape = [B, 1, L, L]\n",
    "        with torch.no_grad():\n",
    "            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n",
    "\n",
    "    @property\n",
    "    def mask(self):\n",
    "        return self._mask\n",
    "\n",
    "# Define FullAttention\n",
    "class FullAttention(nn.Module):\n",
    "    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n",
    "        super(FullAttention, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.mask_flag = mask_flag\n",
    "        self.output_attention = output_attention\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L, H, E = queries.shape\n",
    "        _, S, _, D = values.shape\n",
    "        scale = self.scale or 1. / sqrt(E)\n",
    "\n",
    "        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys)\n",
    "\n",
    "        if self.mask_flag:\n",
    "            if attn_mask is None:\n",
    "                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n",
    "\n",
    "            scores.masked_fill_(attn_mask.mask, -np.inf)\n",
    "\n",
    "        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n",
    "        V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n",
    "\n",
    "        if self.output_attention:\n",
    "            return (V.contiguous(), A)\n",
    "        else:\n",
    "            return (V.contiguous(), None)\n",
    "\n",
    "# Define DataEmbedding_inverted\n",
    "class DataEmbedding_inverted(nn.Module):\n",
    "    def __init__(self, c_in, hidden_size, dropout=0.1):\n",
    "        super(DataEmbedding_inverted, self).__init__()\n",
    "        self.value_embedding = nn.Linear(c_in, hidden_size)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        if x_mark is None:\n",
    "            x = self.value_embedding(x)\n",
    "        else:\n",
    "            x = self.value_embedding(torch.cat([x, x_mark.permute(0, 2, 1)], 1))\n",
    "        return self.dropout(x)\n",
    "\n",
    "# Define the iTransformer model\n",
    "class iTransformer(pl.LightningModule):\n",
    "    def __init__(self, h, input_size, n_series, hidden_size=512, n_heads=8, e_layers=2, d_ff=2048, factor=1, dropout=0.1, use_norm=True, lr=1e-3):\n",
    "        super(iTransformer, self).__init__()\n",
    "        self.h = h\n",
    "        self.input_size = input_size\n",
    "        self.n_series = n_series\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_heads = n_heads\n",
    "        self.e_layers = e_layers\n",
    "        self.d_ff = d_ff\n",
    "        self.factor = factor\n",
    "        self.dropout = dropout\n",
    "        self.use_norm = use_norm\n",
    "        self.lr = lr\n",
    "\n",
    "        self.enc_embedding = DataEmbedding_inverted(input_size, self.hidden_size, self.dropout)\n",
    "\n",
    "        self.encoder = nn.ModuleList([\n",
    "            nn.TransformerEncoderLayer(d_model=self.hidden_size, nhead=self.n_heads, dim_feedforward=self.d_ff, dropout=self.dropout)\n",
    "            for _ in range(self.e_layers)\n",
    "        ])\n",
    "\n",
    "        self.projector = nn.Linear(self.hidden_size, h, bias=True)\n",
    "\n",
    "    def forecast(self, x_enc):\n",
    "        if self.use_norm:\n",
    "            means = x_enc.mean(1, keepdim=True).detach()\n",
    "            x_enc = x_enc - means\n",
    "            stdev = torch.sqrt(torch.var(x_enc, dim=1, keepdim=True, unbiased=False) + 1e-5)\n",
    "            x_enc /= stdev\n",
    "\n",
    "        enc_out = self.enc_embedding(x_enc, None)\n",
    "        for layer in self.encoder:\n",
    "            enc_out = layer(enc_out)\n",
    "\n",
    "        dec_out = self.projector(enc_out).permute(0, 2, 1)[:, :, :self.n_series]\n",
    "\n",
    "        if self.use_norm:\n",
    "            dec_out = dec_out * (stdev[:, 0, :].unsqueeze(1).repeat(1, self.h, 1))\n",
    "            dec_out = dec_out + (means[:, 0, :].unsqueeze(1).repeat(1, self.h, 1))\n",
    "\n",
    "        return dec_out\n",
    "\n",
    "    def forward(self, windows_batch):\n",
    "        insample_y = windows_batch['insample_y'].unsqueeze(-1)  # Add an extra dimension\n",
    "        y_pred = self.forecast(insample_y)\n",
    "        y_pred = y_pred[:, -self.h:, :]\n",
    "        return y_pred\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        output = self(batch)\n",
    "        target = batch['insample_y'][:, -self.h:]\n",
    "        loss = F.mse_loss(output.squeeze(), target)\n",
    "        self.log('train_loss', loss, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        output = self(batch)\n",
    "        target = batch['insample_y'][:, -self.h:]\n",
    "        val_loss = F.mse_loss(output.squeeze(), target)\n",
    "        self.log('val_loss', val_loss, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        mae = F.l1_loss(output.squeeze(), target)\n",
    "        self.log('val_mae', mae, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return {\"val_loss\": val_loss, \"val_mae\": mae}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "# Load the data\n",
    "file_path = '/Users/lennartzahn/Desktop/Masterarbeit/Notebooks (Transformer)/Cleaned_Data_EMA.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df['ds'] = pd.to_datetime(df['ds'])\n",
    "\n",
    "# Filter for a single unique_id (replace 'unique_id_value' with the actual unique_id you want to filter)\n",
    "unique_id_value = 'User #25290'\n",
    "df_single_id = df[df['unique_id'] == unique_id_value]\n",
    "\n",
    "# Split data into train and validation sets\n",
    "train_size = int(len(df_single_id) * 0.8)\n",
    "df_train = df_single_id.iloc[:train_size]\n",
    "df_val = df_single_id.iloc[train_size:]\n",
    "\n",
    "# Define the dataset and dataloader\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, df, input_size, h):\n",
    "        self.df = df\n",
    "        self.input_size = input_size\n",
    "        self.h = h\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df) - self.input_size - self.h + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        insample_y = self.df['y'][idx:idx+self.input_size].values.astype(np.float32)\n",
    "        return {\"insample_y\": torch.tensor(insample_y)}\n",
    "\n",
    "# Set parameters and create dataloader\n",
    "input_size = 16\n",
    "h = 8\n",
    "batch_size = 16\n",
    "\n",
    "train_dataset = TimeSeriesDataset(df_train, input_size, h)\n",
    "val_dataset = TimeSeriesDataset(df_val, input_size, h)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize the model with hyperparameters\n",
    "model = iTransformer(\n",
    "    h=h,\n",
    "    input_size=input_size,\n",
    "    n_series=1,\n",
    "    hidden_size=64,\n",
    "    n_heads=4,\n",
    "    e_layers=2,\n",
    "    d_ff=128,\n",
    "    dropout=0.1,\n",
    "    lr=1e-3,\n",
    ")\n",
    "\n",
    "# Define a PyTorch Lightning Callback for monitoring training\n",
    "class PrintCallback(pl.callbacks.Callback):\n",
    "    def on_epoch_end(self, trainer, pl_module):\n",
    "        print(f'Epoch {trainer.current_epoch} - Train Loss: {trainer.callback_metrics[\"train_loss\"]:.4f}')\n",
    "\n",
    "# Create a callback to log the loss\n",
    "class LossLogger(pl.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_epoch_end(self, trainer, pl_module):\n",
    "        # Retrieve the logged losses\n",
    "        loss = trainer.callback_metrics.get('train_loss')\n",
    "        if loss is not None:\n",
    "            self.losses.append(loss.item())\n",
    "\n",
    "loss_logger = LossLogger()\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=20, callbacks=[PrintCallback(), loss_logger], default_root_dir='/Users/lennartzahn/Desktop/Masterarbeit/Notebooks (Transformer)')\n",
    "trainer.fit(model, train_dataloader, val_dataloader)\n",
    "\n",
    "# Define the prediction function\n",
    "def predict(model, dataloader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            output = model(batch)\n",
    "            predictions.append(output.numpy())\n",
    "    return np.concatenate(predictions)\n",
    "\n",
    "# Example prediction\n",
    "predictions = predict(model, val_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_predictions(predictions, actuals):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(actuals, label='Actual Values')\n",
    "    plt.plot(predictions, label='Predicted Values')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Values')\n",
    "    plt.title('Predictions vs Actuals')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
